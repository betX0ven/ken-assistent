from sentence_transformers import SentenceTransformer, util
import numpy as np
import pandas as pd
import pymorphy3
import re
import os

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import Pipeline
import joblib



morph = pymorphy3.MorphAnalyzer()

model = SentenceTransformer("sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2")

all_answers = ['–ø–æ–≥–æ–¥–∞', '–≤—Ä–µ–º—è', '—Å—Ç–∏–º', '–±—Ä–∞—É–∑–µ—Ä', '–º—É–∑—ã–∫–∞']
banword = ["–∫–∞–∫, –æ–Ω, –º—ã, –µ–≥–æ, –≤—ã, –≤–∞–º, –≤–∞—Å, –µ–µ, —á—Ç–æ, –∫–æ—Ç–æ—Ä—ã–π, –∏—Ö, –≤—Å–µ, –æ–Ω–∏, —è, –≤–µ—Å—å, –º–Ω–µ, –º–µ–Ω—è, —Ç–∞–∫–∏–º, –¥–ª—è, –Ω–∞, –ø–æ, —Å–æ, –∏–∑, –æ—Ç, –¥–æ, –±–µ–∑, –Ω–∞–¥, –ø–æ–¥, –∑–∞, –ø—Ä–∏, –ø–æ—Å–ª–µ, –≤–æ, –∂–µ, —Ç–æ, –±—ã, –≤—Å–µ–≥–æ, –∏—Ç–æ–≥–æ, –¥–∞–∂–µ, –¥–∞, –Ω–µ—Ç, –æ–π, –æ–≥–æ, —ç—Ö, –±—Ä–∞–≤–æ, –∑–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ, —Å–ø–∞—Å–∏–±–æ, –∏–∑–≤–∏–Ω–∏—Ç–µ, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞".replace(",","").split()][0]

tags = [i for i in all_answers]
text_embeddings = model.encode(tags, convert_to_tensor=True)

def semantic_search(query, embeddings, top_n=3):
    query_embedding = model.encode(query, convert_to_tensor=True)

    similarities = util.pytorch_cos_sim(query_embedding, embeddings)[0]

    top_results = np.argsort(similarities.cpu().numpy())[-top_n:][::-1]
    
    if float(similarities[top_results[0]]) > 0.53:
        return all_answers[top_results[0]]
    else:
        return "for_ai"
    
def start_ai(query):
    response = semantic_search(query, text_embeddings)
    return response

def preparing_query(query):
    total_query = ''
    for word in query.split():
        word = morph.parse(word)[0]
        total_query+=word.normal_form+" "
    return total_query

def final_query_handler(query):
    print('–ó–∞–ø—Ä–æ—Å: ' + query)
    return start_ai(preparing_query(query))


training_data = [
    # –ö–æ–º–∞–Ω–¥—ã
    ("—Å–æ–∑–¥–∞–π 3d –º–æ–¥–µ–ª—å —Ä–µ–∞–∫—Ç–æ—Ä–∞", "command"),
    ("–≤–∫–ª—é—á–∏ –≤—Å–µ —Å–∏—Å—Ç–µ–º—ã", "command"),
    ("–ø—Ä–æ—Å–∫–∞–Ω–∏—Ä—É–π —Ç–µ—Ä—Ä–∏—Ç–æ—Ä–∏—é", "command"),
    ("—Ä–∞—Å—Å—á–∏—Ç–∞–π —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏—é –ø–æ–ª—ë—Ç–∞", "command"),
    ("–ø–æ–∫–∞–∂–∏ –≥–æ–ª–æ–≥—Ä–∞–º–º—É", "command"),
    ("–∞–∫—Ç–∏–≤–∏—Ä—É–π –ø—Ä–æ—Ç–æ–∫–æ–ª", "command"),
    ("–∑–∞–ø—É—Å—Ç–∏ —Å–∏–º—É–ª—è—Ü–∏—é", "command"),
    ("–≤—ã–∫–ª—é—á–∏ –ø–∏—Ç–∞–Ω–∏–µ", "command"),
    ("–ø–æ—Å—Ç—Ä–æ–π –≥—Ä–∞—Ñ–∏–∫", "command"),
    ("–Ω–∞–π–¥–∏ —É—è–∑–≤–∏–º–æ—Å—Ç–∏", "command"),
    
    # –î–∏–∞–ª–æ–≥–∏
    ("–∫–∞–∫ –¥—É–º–∞–µ—à—å —ç—Ç–æ —Å—Ä–∞–±–æ—Ç–∞–µ—Ç", "dialog"),
    ("–ø–æ—á–µ–º—É –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç —Å–∏—Å—Ç–µ–º–∞", "dialog"),
    ("—á—Ç–æ –µ—Å–ª–∏ –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –¥—Ä—É–≥–æ–π —Å–ø–æ—Å–æ–±", "dialog"),
    ("–∏–Ω—Ç–µ—Ä–µ—Å–Ω–æ –ø–æ—á–µ–º—É –æ–Ω —Ç–∞–∫ –ø–æ—Å—Ç—É–ø–∏–ª", "dialog"),
    ("–º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–∞–º —Å—Ç–æ–∏—Ç –ø–µ—Ä–µ–¥—É–º–∞—Ç—å", "dialog"),
    ("–∫–∞–∫ —Ç–µ–±–µ —Ç–∞–∫–∞—è –∏–¥–µ—è", "dialog"),
    ("–æ–±—ä—è—Å–Ω–∏ –ø—Ä–∏–Ω—Ü–∏–ø —Ä–∞–±–æ—Ç—ã", "dialog"),
    ("–∑–∞—á–µ–º –Ω–∞–º —ç—Ç–æ –Ω—É–∂–Ω–æ", "dialog"),
    ("—á—Ç–æ —Ç—ã –æ–± —ç—Ç–æ–º –¥—É–º–∞–µ—à—å", "dialog"),
    ("–∫–∞–∫ —É–ª—É—á—à–∏—Ç—å –∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏—é", "dialog"),
    ("—Ä–∞—Å—Å–∫–∞–∂–∏ –ø—Ä–æ —ç—Ç–æ", "dialog"),
    
    # –°–ª–æ–∂–Ω—ã–µ —Å–ª—É—á–∞–∏
    ("–ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –∏ —Å–∫–∞–∂–∏ –º–Ω–µ–Ω–∏–µ", "command"), # –∫–æ–º–∞–Ω–¥–∞ + –¥–∏–∞–ª–æ–≥ = –∫–æ–º–∞–Ω–¥–∞
    ("—Ä–∞—Å—Å–∫–∞–∂–∏ –∫–∞–∫ —ç—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç", "dialog"), # –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –∫–æ–º–∞–Ω–¥–∞–º
]

class QueryClassify():
    def __init__(self):
        self.pipeline = Pipeline([
            ('tfidf', TfidfVectorizer(
                lowercase=True,
                ngram_range=(1, 2),  
                max_features=1000
            )),
            ('classifier', LogisticRegression(
                random_state=42,
                class_weight='balanced'
            ))
        ])
        
    def preparing(self, text):
        text = text.lower().strip()
        text = re.sub(r'[^\w\s]', '', text) 
        return text
    
    def train(self, texts, labels):
        self.pipeline.fit(texts, labels)
    
    def predict(self, text):
        prepared_query = self.preparing(text)
        
        prediction = self.pipeline.predict([prepared_query])[0]
        probability = np.max(self.pipeline.predict_proba([prepared_query]))
        
        return prediction, probability
    
    def save_model(self, path):
        joblib.dump(self.pipeline, path)
    
    def load_model(self, path):
        pass

def create_and_train_classifier():
    # –†–∞–∑–¥–µ–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –Ω–∞ —Ç–µ–∫—Å—Ç—ã –∏ –º–µ—Ç–∫–∏
    texts, labels = zip(*training_data)
    
    # –°–æ–∑–¥–∞–µ–º –∏ –æ–±—É—á–∞–µ–º –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä
    classifier = QueryClassify()
    classifier.train(texts, labels)
    
    return classifier


def test_classifier(classifier):
    test_phrases = [
        "—Å–æ–∑–¥–∞–π –Ω–æ–≤—É—é –±—Ä–æ–Ω—é –¥–ª—è –º–µ–Ω—è",
        "–∫–∞–∫ –¥—É–º–∞–µ—à—å –∫–∞–∫–æ–π –º–µ—Ç–∞–ª–ª –ª—É—á—à–µ",
        "–≤–∫–ª—é—á–∏ —Å–∏—Å—Ç–µ–º—É –Ω–µ–≤–∏–¥–∏–º–æ—Å—Ç–∏ —Å–µ–π—á–∞—Å –∂–µ",
        "–ø–æ—á–µ–º—É –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç —Ä–µ–∞–∫—Ç–æ—Ä",
        "–º–æ–∂–µ—Ç —Å—Ç–æ–∏—Ç –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –≤–∏–±—Ä–∞–Ω–∏—É–º",
        "–ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —ç—Ç—É —Å—Ö–µ–º—É –∏ –¥–∞–π –æ—Ü–µ–Ω–∫—É",
        "—á—Ç–æ –µ—Å–ª–∏ –º—ã –≤—Å—ë –¥–µ–ª–∞–µ–º –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ",
        "–∑–∞–ø—É—Å—Ç–∏ –ø—Ä–æ—Ç–æ–∫–æ–ª –æ—á–∏—Å—Ç–∫–∏ –ø–∞–º—è—Ç–∏",
        "–∏–Ω—Ç–µ—Ä–µ—Å–Ω–æ —Å—Ä–∞–±–æ—Ç–∞–µ—Ç –ª–∏ —ç—Ç–æ—Ç –∞–ª–≥–æ—Ä–∏—Ç–º",
        "–ø–æ—Å—Ç—Ä–æ–π –≥—Ä–∞—Ñ–∏–∫ —ç–Ω–µ—Ä–≥–æ–ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏—è"
    ]

    for phrase in test_phrases:
        intent, confidence = classifier.predict(phrase)
        status = "‚úÖ" if confidence > 0.7 else "‚ö†Ô∏è"

# def interactive_mode(classifier):
#     print("\nü§ñ –†–ï–ñ–ò–ú –î–ò–ê–õ–û–ì–ê (–¥–ª—è –≤—ã—Ö–æ–¥–∞ –≤–≤–µ–¥–∏ 'exit')")
#     print("-" * 40)
    
#     while True:
#         user_input = input("–¢—ã: ").strip()
        
#         if user_input.lower() in ['exit', '–≤—ã—Ö–æ–¥']:
#             break
        
#         intent, confidence = classifier.predict(user_input)
        
#         if intent == "unclear":
#             print("–î–∂–∞—Ä–≤–∏—Å: –ù–µ —Å–æ–≤—Å–µ–º –ø–æ–Ω—è–ª. –≠—Ç–æ –∫–æ–º–∞–Ω–¥–∞ –∫ –¥–µ–π—Å—Ç–≤–∏—é –∏–ª–∏ –ø—Ä–æ—Å—Ç–æ —Ä–∞–∑–º—ã—à–ª–µ–Ω–∏–µ?")
#         elif intent == "command":
#             print(f"–î–∂–∞—Ä–≤–∏—Å: –í—ã–ø–æ–ª–Ω—è—é –∫–æ–º–∞–Ω–¥—É (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {confidence:.2f})")
#         else:  # dialog
#             print(f"–î–∂–∞—Ä–≤–∏—Å: –û–±–¥—É–º—ã–≤–∞—é —Ç–≤–æ–π –≤–æ–ø—Ä–æ—Å (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {confidence:.2f})")

def query_classify(query):
    classifier = create_and_train_classifier()
    test_classifier(classifier)
    if os.path.exists("intent_classifier.pkl"):
        classifier.load_model("intent_classifier.pkl")
    else:
        classifier = create_and_train_classifier()
        classifier.save_model("intent_classifier.pkl")
        
    intent, confidence = classifier.predict(query)
    if intent == "unclear":
        print("–•–∑")
        return 'null'
    elif intent == "command":
        print(f"–ö–æ–º–∞–Ω–¥–∞, {confidence:.2f})")
        return 'command'
    else:  # dialog
        print(f"–î–∏–∞–ª–æ–≥, {confidence:.2f})")
        return 'dialog'
